# Functional Data Engineering - A Set of Best Practices 

## Services

Data engineers are operating at a higher level of abstraction and in some cases that means providing services and tooling to automate the type of work that data engineers, data scientists or analysts may do manually.

* **data ingestion**: services and tooling around “scraping” databases, loading logs, fetching data from external stores or APIs, …
* **metric computation**: frameworks to compute and summarize engagement, growth or segmentation related metrics
* **anomaly detection**: automating data consumption to alert people anomalous events occur or when trends are changing significantly
* **metadata management**: tooling around allowing generation and consumption of metadata, making it easy to find information in and around the data warehouse
* **experimentation**: A/B testing and experimentation frameworks is often a critical piece of company’s analytics with a significant data engineering component to it
* **instrumentation**: analytics starts with logging events and attributes related to those events, data engineers have vested interests in making sure that high quality data is captured upstream
* **sessionization**: pipelines that are specialized in understand series of actions in time, allowing analysts to understand user behaviors